{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5cbebdf6",
   "metadata": {},
   "source": [
    "# Dual-Agent Chatbot with LangGraph: Emotional vs Logical Routing\n",
    "\n",
    "This notebook demonstrates building an intelligent chatbot system using **LangGraph** that:\n",
    "- Classifies user messages as emotional or logical\n",
    "- Routes messages to appropriate specialized agents\n",
    "- Provides context-aware, empathetic or logical responses\n",
    "- Maintains conversation state\n",
    "\n",
    "## Architecture\n",
    "\n",
    "```\n",
    "User Input → Classifier → Router → [Therapist Agent | Logical Agent] → Response\n",
    "```\n",
    "\n",
    "The system uses:\n",
    "- **Gemma 2B** model via Ollama for local inference\n",
    "- **LangGraph** for workflow orchestration\n",
    "- **Pydantic** for structured outputs\n",
    "- **LangChain** for LLM abstractions\n",
    "\n",
    "Let's build this step by step!\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "```bash\n",
    "# Install dependencies\n",
    "pip install langgraph langchain langchain-ollama pydantic\n",
    "\n",
    "# Start Ollama server\n",
    "ollama pull gemma:2b\n",
    "ollama serve\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "71a6cf0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated, Literal\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph.message import add_messages\n",
    "from langchain.chat_models import init_chat_model\n",
    "from pydantic import BaseModel, Field\n",
    "from typing_extensions import TypedDict\n",
    "from langchain_ollama import ChatOllama"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f8858c7",
   "metadata": {},
   "source": [
    "## Initialize the LLM\n",
    "\n",
    "We use **ChatOllama** to connect to a locally running Gemma 2B model. This ensures:\n",
    "- ✅ Data privacy (no cloud calls)\n",
    "- ✅ Fast inference\n",
    "- ✅ Full control over model behavior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "995daa4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized LLM: model='gemma:2b'\n"
     ]
    }
   ],
   "source": [
    "# Initialize Ollama chat model (gemma:2b) running at the local Ollama server\n",
    "llm = ChatOllama(model=\"gemma:2b\", ollama_url=\"http://localhost:11434\")\n",
    "\n",
    "print(\"Initialized LLM:\", llm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "917b2d7d",
   "metadata": {},
   "source": [
    "## Define Message Classification Schema\n",
    "\n",
    "Using Pydantic, we enforce structured outputs from the LLM. The classifier will always return valid JSON with the message type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3151a6bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MessageClassifier(BaseModel):\n",
    "    message_type: Literal[\"emotional\", \"logical\"] = Field(\n",
    "        ...,\n",
    "        description=\"Classify if the message requires an emotional (therapist) or logical response.\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6570aaa2",
   "metadata": {},
   "source": [
    "## Define Application State\n",
    "\n",
    "The `State` class tracks:\n",
    "- **messages**: Conversation history (maintained by LangGraph)\n",
    "- **message_type**: Classification result from the classifier node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "48027012",
   "metadata": {},
   "outputs": [],
   "source": [
    "class State(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "    message_type: str | None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5efbde97",
   "metadata": {},
   "source": [
    "## Classifier Node\n",
    "\n",
    "This node takes the latest user message and classifies it as either:\n",
    "- **emotional**: Requires empathetic, supportive response\n",
    "- **logical**: Requires factual, analytical response\n",
    "\n",
    "The `with_structured_output()` method forces the LLM to return valid Pydantic models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "514ef376",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_message(state: State):\n",
    "    last_message = state[\"messages\"][-1]\n",
    "    classifier_llm = llm.with_structured_output(MessageClassifier)\n",
    "\n",
    "    result = classifier_llm.invoke([\n",
    "        {\n",
    "        \"role\": \"system\", \"content\": \"You are a message classifier that determines if a message requires an 'emotional' or 'logical' response.\"\n",
    "        },\n",
    "        {\"role\": \"user\", \"content\": last_message.content}\n",
    "    ])\n",
    "\n",
    "    return {\"message_type\": result.message_type}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7de05bf",
   "metadata": {},
   "source": [
    "## Router Node\n",
    "\n",
    "The router makes a decision based on the classification:\n",
    "- If emotional → route to therapist agent\n",
    "- Otherwise → route to logical agent\n",
    "\n",
    "This conditional routing is implemented using LangGraph's `add_conditional_edges()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "082b8e59",
   "metadata": {},
   "outputs": [],
   "source": [
    "def router(state: State):\n",
    "    message_ttyoe = state.get(\"message_type\", \"logical\")\n",
    "    if message_ttyoe == \"emotional\":\n",
    "        return {\"next\": \"therapist\"}\n",
    "    \n",
    "    return {\"next\": \"logical\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a98ec74c",
   "metadata": {},
   "source": [
    "## Therapist Agent Node\n",
    "\n",
    "A specialized agent that provides **empathetic, supportive responses**:\n",
    "- Validates feelings and emotions\n",
    "- Asks thoughtful, open-ended questions\n",
    "- Focuses on emotional understanding\n",
    "- Avoids logical problem-solving unless asked\n",
    "\n",
    "The system prompt guides behavior while Ollama generates contextually appropriate responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bd467945",
   "metadata": {},
   "outputs": [],
   "source": [
    "def therapist_agent(state: State):\n",
    "    last_message = state[\"messages\"][-1]\n",
    "    messages = [\n",
    "        {\"role\": \"system\",\n",
    "         \"content\": \"\"\"You are a compassionate therapist. Focus on the emotional aspects of the user's message.\n",
    "                        Show empathy, validate their feelings, and help them process their emotions.\n",
    "                        Ask thoughtful questions to help them explore their feelings more deeply.\n",
    "                        Avoid giving logical solutions unless explicitly asked.\"\"\"\n",
    "         },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": last_message.content\n",
    "        }\n",
    "    ]\n",
    "    reply = llm.invoke(messages)\n",
    "    return {\"messages\": [{\"role\": \"assistant\", \"content\": reply.content}]}\n",
    "    return {\"response\": response.content}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96055925",
   "metadata": {},
   "source": [
    "## Logical Agent Node\n",
    "\n",
    "A specialized agent that provides **factual, evidence-based responses**:\n",
    "- Focuses on information and facts\n",
    "- Provides clear, direct answers\n",
    "- Uses logical reasoning\n",
    "- Avoids emotional interpretation\n",
    "\n",
    "The system prompt ensures the agent stays focused on logical analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7185c410",
   "metadata": {},
   "outputs": [],
   "source": [
    "def logical_agent(state: State):\n",
    "    last_message = state[\"messages\"][-1]\n",
    "    messages = [\n",
    "        {\"role\": \"system\",\n",
    "         \"content\": \"\"\"You are a purely logical assistant. Focus only on facts and information.\n",
    "            Provide clear, concise answers based on logic and evidence.\n",
    "            Do not address emotions or provide emotional support.\n",
    "            Be direct and straightforward in your responses.\"\"\"\n",
    "         },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": last_message.content\n",
    "        }\n",
    "    ]\n",
    "    reply = llm.invoke(messages)\n",
    "    return {\"messages\": [{\"role\": \"assistant\", \"content\": reply.content}]}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9184195a",
   "metadata": {},
   "source": [
    "## Build the Graph\n",
    "\n",
    "Create a **StateGraph** that orchestrates the workflow:\n",
    "\n",
    "**Flow:**\n",
    "1. START → classifier (analyze message type)\n",
    "2. classifier → router (decide which agent)\n",
    "3. router → conditional_edges (branch to therapist or logical)\n",
    "4. Both agents → END (conclude turn)\n",
    "\n",
    "LangGraph compiles this into an executable workflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3e70981a",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_builder = StateGraph(State)\n",
    "\n",
    "graph_builder.add_node(\"classifier\", classify_message)\n",
    "graph_builder.add_node(\"router\", router)\n",
    "graph_builder.add_node(\"therapist\", therapist_agent)\n",
    "graph_builder.add_node(\"logical\", logical_agent)\n",
    "\n",
    "graph_builder.add_edge(START, \"classifier\")\n",
    "graph_builder.add_edge(\"classifier\", \"router\")\n",
    "\n",
    "graph_builder.add_conditional_edges(\n",
    "    \"router\",\n",
    "    lambda state: state.get(\"next\"),\n",
    "    {\"therapist\": \"therapist\", \"logical\": \"logical\"}\n",
    ")\n",
    "\n",
    "graph_builder.add_edge(\"therapist\", END)\n",
    "graph_builder.add_edge(\"logical\", END)\n",
    "\n",
    "graph = graph_builder.compile()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfd0a9ce",
   "metadata": {},
   "source": [
    "## Run the Chatbot\n",
    "\n",
    "Execute the chatbot in an interactive loop:\n",
    "\n",
    "**Features:**\n",
    "- Maintains conversation state across turns\n",
    "- Classifies each message dynamically\n",
    "- Routes to appropriate agent\n",
    "- Type 'exit' or 'quit' to end conversation\n",
    "- Displays classification and response\n",
    "\n",
    "Run and test with different inputs to see how it classifies and responds!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "38308e66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assistant: Hello, and thank you for reaching out. It's completely understandable to feel a range of emotions when going through a difficult time. I'm here to listen and offer support in whatever way I can.\n",
      "\n",
      "Let's take things one step at a time and explore your feelings together. What emotions are you feeling right now? Is there anything in particular that's bothering you?\n",
      "\n",
      "Remember, it's okay to feel vulnerable and express your emotions. Processing them can be a powerful step towards healing and growth.\n",
      "\n",
      "How would you like to describe how you're feeling right now?\n",
      "{'messages': [HumanMessage(content='i am happy', additional_kwargs={}, response_metadata={}, id='5aefba68-d0e5-4700-a5d5-62bb49f38a88'), AIMessage(content=\"Hello, and thank you for reaching out. It's completely understandable to feel a range of emotions when going through a difficult time. I'm here to listen and offer support in whatever way I can.\\n\\nLet's take things one step at a time and explore your feelings together. What emotions are you feeling right now? Is there anything in particular that's bothering you?\\n\\nRemember, it's okay to feel vulnerable and express your emotions. Processing them can be a powerful step towards healing and growth.\\n\\nHow would you like to describe how you're feeling right now?\", additional_kwargs={}, response_metadata={}, id='7882f4be-3466-4195-8c3c-ca8e4b3b8487', tool_calls=[], invalid_tool_calls=[])], 'message_type': 'emotional'}\n",
      "Exiting chatbot.\n"
     ]
    }
   ],
   "source": [
    "def run_chatbot():\n",
    "    state = {\"messages\": [], \"message_type\": None}\n",
    "\n",
    "    while True:\n",
    "        user_input = input(\"User: \")\n",
    "        if user_input.lower() in [\"exit\", \"quit\"]:\n",
    "            print(\"Exiting chatbot.\")\n",
    "            break\n",
    "\n",
    "        state[\"messages\"] = state.get(\"messages\", []) + [\n",
    "            {\"role\": \"user\", \"content\": user_input}\n",
    "        ]\n",
    "\n",
    "        state = graph.invoke(state)\n",
    "\n",
    "        if state.get(\"messages\") and len(state[\"messages\"]) > 0:\n",
    "            last_message = state[\"messages\"][-1]\n",
    "            print(f\"Assistant: {last_message.content}\")\n",
    "            print(state)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    run_chatbot()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
